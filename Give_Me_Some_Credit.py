# -*- coding: utf-8 -*-
"""Untitled38.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qYKiN8ksX8ZVZKAiXPXqBpXKxcC7FAkT
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn

data = pd.read_csv('/content/cs-training.csv')
data.head()
data=data.iloc[:,1:]
type(data)

"""Exploration of Data"""

data.info()

"""Finding null values"""

data.isnull().sum()

data[data['MonthlyIncome'].isnull()][['NumberOfDependents','DebtRatio']].describe()

"""Dealing with missing values"""

data['DebtRatio'].describe()

"""Calculating the 50% of Monthly income from the data who has debt ratiop greater then 1"""

data[(data['MonthlyIncome'].notnull())&(data['DebtRatio']>1)]['MonthlyIncome'].describe()

data.isnull().sum()

data.shape

"""Filling the null value in Monthly income with mean"""

data['MonthlyIncome'].fillna(value=1157, inplace=True)
data['NumberOfDependents'].fillna(value=0, inplace=True)

data.isnull().sum()

data.shape

"""Exploration of data COlumn by column"""

data.boxplot(column='RevolvingUtilizationOfUnsecuredLines')
data['RevolvingUtilizationOfUnsecuredLines'][(data['RevolvingUtilizationOfUnsecuredLines']>5)].describe()

import seaborn as s
s.boxplot(x = data[data['RevolvingUtilizationOfUnsecuredLines']>5]['RevolvingUtilizationOfUnsecuredLines'])

s.boxplot(x = data[data['RevolvingUtilizationOfUnsecuredLines']<1]['RevolvingUtilizationOfUnsecuredLines'])

"""Removing Data that are greater than 95% Quantile value of RevolvingUtilizationOfUnsecuredLines"""

data[data['RevolvingUtilizationOfUnsecuredLines'] >5]['RevolvingUtilizationOfUnsecuredLines'].count()/len(data) * 100

data = data[data['RevolvingUtilizationOfUnsecuredLines'] <=5]
data.describe()
data.shape

"""AGE"""

s.histplot(data['age'], binwidth=3)

data['age'].value_counts().sort_index()

"""replacing age of 0 with median value of age"""

data['age'].replace(to_replace= 0, value=data['age'].median(), inplace=True)
data['age'].value_counts().sort_index()
data.shape

data["NumberOfTimes90DaysLate"].value_counts().sort_index()

data["NumberOfTime60-89DaysPastDueNotWorse"].value_counts().sort_index()

data["NumberOfTime30-59DaysPastDueNotWorse"].value_counts().sort_index()

plt.figure(figsize=(10,5))

numberPastDue = data[['NumberOfTime60-89DaysPastDueNotWorse', 'NumberOfTimes90DaysLate', 'NumberOfTime30-59DaysPastDueNotWorse']]
s.boxplot(data = numberPastDue)

data[data['NumberOfTime30-59DaysPastDueNotWorse'] > 20].mean()

pd.DataFrame({'below_1': data[data['DebtRatio'] < 1]['DebtRatio'].count()/len(data)*100,
             'beyond_10': data[data['DebtRatio'] >10]['DebtRatio'].count()/len(data)*100,
             'between_1-10': data[(data['DebtRatio'] > 1) & (data['DebtRatio'] <= 10)]['DebtRatio'].count()/len(data)*100
             }, index=[1])

s.countplot(data['SeriousDlqin2yrs'])

data['SeriousDlqin2yrs'].value_counts().sort_index()

X = data.drop('SeriousDlqin2yrs', axis=1)
y = data['SeriousDlqin2yrs']
X.shape
y.shape

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 8)
x_train.shape

from sklearn.ensemble import RandomForestClassifier

parameter = {
    'n_estimators': [9,18,27,36],
    'max_depth': [3,5,7,9],
    'min_samples_leaf': [2, 4, 6]
}

random_forest = RandomForestClassifier()

from sklearn.model_selection import RandomizedSearchCV

random_forest_model = RandomizedSearchCV(random_forest, param_distributions=parameter, cv=7)

random_forest_model.fit(x_train, y_train)

best_estimator_rf = random_forest_model.best_estimator_
best_estimator_rf

y_ped_tandom_forest = random_forest_model.predict(x_test)
y_ped_tandom_forest.shape

y_ped_tandom_forest

from sklearn.metrics import confusion_matrix
con_matrix = confusion_matrix(y_test, y_ped_tandom_forest)
print(con_matrix)

plt.figure()
con_matrix2 = confusion_matrix(y_test, y_ped_tandom_forest, normalize='true')
s.heatmap(con_matrix2, annot=True)
plt.xlabel('Prediction')
plt.ylabel('Target')
plt.title(' Confusion Matrix Validation ');

from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, plot_roc_curve
plot_roc_curve(random_forest_model, x_test, y_test)

print("training accuracy: {:.2f}".format(random_forest_model.score(x_train, y_train) * 100))
print("validation accuracy: {:.2f}".format(random_forest_model.score(x_test, y_test) * 100))

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score

Rf_auc = roc_auc_score(y_test, y_ped_tandom_forest)
print('Random forest: ROC AUC=%.3f' % (Rf_auc))

"""Using XGBoost Algorithm"""

import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.model_selection import GridSearchCV
def algorithm_pipeline(x_train, x_test, y_train, y_test, 
                       model, xgb_hyperparams, cv=10):
    gs = GridSearchCV(
        estimator=model,
        param_grid=xgb_hyperparams, 
        cv=cv, 
        n_jobs=-1, 
        
        verbose=2
    )
    fitted_model = gs.fit(x_train, y_train)

    pred_XGB = fitted_model.predict(x_test)

    
    return fitted_model, pred_XGB

xgb_hyperparams = {
    'max_depth' : np.arange(4,10,1),
    'colsample_bytree' : np.arange(0.5,1,0.1),
    'learning_rate' : [0.01, 0.1, 0.2, 0.3],
    'n_estimators' : np.arange(400,1000,100),
    'subsample': np.arange(0.5,1,0.1),
    'scale_pos_weight': [10,15,20]

    
}
XGB_model = xgb.XGBClassifier()

#XGB_model, pred_XGB = algorithm_pipeline(x_train, x_test, y_train, y_test, XGB_model, 
                                 #xgb_hyperparams, cv=2)

xgb_model_new = xgb.XGBClassifier(n_jobs = -1, n_estimators = 220, random_state= 2)
xgb_model_new.fit(x_train, y_train)

ypred_xgb= xgb_model_new .predict(x_test)
ypred_xgb

axis1 = s.countplot(ypred_xgb)
plt.title('Prediction of Test Data')
plt.xlabel('SeriousDLQ in 2 Years')
plt.ylabel('Count')
for p in axis1.patches:
        axis1.annotate('{:,}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))

print("training accuracy with XGB model: {:.2f}".format(xgb_model_new.score(x_train, y_train) * 100))
print("validation accuracy with XGB model: {:.2f}".format(xgb_model_new.score(x_test, y_test) * 100))

xgb_auc = roc_auc_score(y_test, ypred_xgb)
print('XGB: ROC AUC=%.3f' % (xgb_auc))

plot_roc_curve(xgb_model_new, x_test, y_test)

test_data = pd.read_csv('/content/cs-test.csv')
test_data.head()
test_data=test_data.iloc[:,1:]
type(test_data)

test_data.describe()

test_data.isnull().sum()

test_data[(test_data['MonthlyIncome'].notnull())&(test_data['DebtRatio']>1)]['MonthlyIncome'].describe()

test_data['MonthlyIncome'].fillna(value=1666, inplace=True)
test_data['NumberOfDependents'].fillna(value=0, inplace=True)

test_data.isnull().sum()

X_test_data = test_data.drop('SeriousDlqin2yrs', axis=1)
y_test_data= test_data['SeriousDlqin2yrs']
X_test_data.shape
y_test_data.shape

X_test_data.isnull().sum()

ypred_xgb_test_data = xgb_model_new .predict(X_test_data)
print(ypred_xgb_test_data)

axis = s.countplot(ypred_xgb_test_data)
plt.title('Prediction of Test Data')
plt.xlabel('SeriousDLQ in 2 Years')
plt.ylabel('Count')
for p in axis.patches:
        axis.annotate('{:,}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+50))